{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "clinical-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reDirection(url):\n",
    "    pos = url.rfind(\"//\")    #Finds last occurence of // in url\n",
    "    \n",
    "    if pos<7:\n",
    "        return 0\n",
    "    \n",
    "    if url[:5].upper()==\"HTTPS\" and pos==7:\n",
    "        return 0\n",
    "    \n",
    "    return 1    # only 1 // must be present and that only at index less than 7\n",
    "print(reDirection(\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"))\n",
    "reDirection(\"http://davidforrest.org//davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "former-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'broser', '6716804bc5a91f707a34479012dad47c', '']\n",
      "2\n",
      "['', 'davidforrest.us', 'wawaa', 'content', '9cf311d77fc743a7a444a0ba0df5650c', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(getDepth(\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"))\n",
    "getDepth(\"http://davidforrest.org/davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_fun(url):\n",
    "    return 1\n",
    "my_fun(\"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crude-venezuela",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'urlparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5d3c0548a38b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttpDomain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mhttpDomain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://davidforrest.org/davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5d3c0548a38b>\u001b[0m in \u001b[0;36mhttpDomain\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhttpDomain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mdomain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;34m'https'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'urlparse' is not defined"
     ]
    }
   ],
   "source": [
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "print(httpDomain(\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"))\n",
    "httpDomain(\"http://davidforrest.org/davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-begin",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-18ba4e71f9fb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-18ba4e71f9fb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install numpy\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "annual-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\n",
      "ERROR: Could not find a version that satisfies the requirement urlparse (from versions: none)\n",
      "ERROR: No matching distribution found for urlparse\n"
     ]
    }
   ],
   "source": [
    "!pip install urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.16.6-cp27-cp27m-win_amd64.whl (11.9 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "august-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brazilian-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abandoned-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from urllib.parse import urlparse\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "print(httpDomain(\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"))\n",
    "httpDomain(\"http://davidforrest.org/davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adolescent-yahoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from urllib.parse import urlparse\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "print(httpDomain(\"http://95.154.196.187/broser/6716804bc5a91f707a34479012dad47c/\"))\n",
    "httpDomain(\"http://davidforrest.org/davidforrest.us/wawaa/content/9cf311d77fc743a7a444a0ba0df5650c/?user=jim@thejimburkefamily.com&amp;_verify?service=mail&amp;data:text/html;charset=utf-8;base64\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-currency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parse\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
      "Using legacy 'setup.py install' for parse, since package 'wheel' is not installed.\n",
      "Installing collected packages: parse\n",
      "    Running setup.py install for parse: started\n",
      "    Running setup.py install for parse: finished with status 'done'\n",
      "Successfully installed parse-1.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focused-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "import re\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "tinyURL(\"https://bitly.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "descending-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "import parse \n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n",
    "    print(urlparse(url).netloc)\n",
    "prefixSuffix(\"https://bit-ly.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stable-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re\n",
      "ERROR: No matching distribution found for re\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "helpful-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-whois\n",
      "  Downloading python-whois-0.7.3.tar.gz (91 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Using legacy 'setup.py install' for python-whois, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: future, python-whois\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "    Running setup.py install for python-whois: started\n",
      "    Running setup.py install for python-whois: finished with status 'done'\n",
      "Successfully installed future-0.18.2 python-whois-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install python-whois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structural-gathering",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-34f75781efff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mweb_traffic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.facebook.com/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-34f75781efff>\u001b[0m in \u001b[0;36mweb_traffic\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Filling the whitespaces in the URL if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \"REACH\")['RANK']\n\u001b[0;32m     14\u001b[0m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mbuilder_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuilder_class\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                 raise FeatureNotFound(\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "#import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "# 12.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "  try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "    url = urllib.parse.quote(url)\n",
    "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "    rank = int(rank)\n",
    "  except TypeError:\n",
    "        return 1\n",
    "  if rank <100000:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "web_traffic(\"https://www.facebook.com/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polish-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "positive-paper",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-34f75781efff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mweb_traffic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.facebook.com/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-34f75781efff>\u001b[0m in \u001b[0;36mweb_traffic\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Filling the whitespaces in the URL if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \"REACH\")['RANK']\n\u001b[0;32m     14\u001b[0m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mbuilder_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuilder_class\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                 raise FeatureNotFound(\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "#import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "# 12.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "  try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "    url = urllib.parse.quote(url)\n",
    "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "    rank = int(rank)\n",
    "  except TypeError:\n",
    "        return 1\n",
    "  if rank <100000:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "web_traffic(\"https://www.facebook.com/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "referenced-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement parser\n",
      "ERROR: No matching distribution found for parser\n"
     ]
    }
   ],
   "source": [
    "!pip install parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worthy-value",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='www.facebook.com', path='/', params='', query='', fragment='')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ParseResult' object has no attribute 'creation_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf4ac6f9b942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m       \u001b[0mage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdomainAge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetDomain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.facebook.com/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-cf4ac6f9b942>\u001b[0m in \u001b[0;36mdomainAge\u001b[1;34m(domain_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdomainAge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdomain_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m   \u001b[0mcreation_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomain_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreation_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m   \u001b[0mexpiration_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomain_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpiration_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreation_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpiration_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ParseResult' object has no attribute 'creation_date'"
     ]
    }
   ],
   "source": [
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "from urllib.parse import urlparse,urlencode\n",
    "def getDomain(url):\n",
    "    result= urlparse(url)\n",
    "    domain = result\n",
    "    print(domain)\n",
    "    return domain\n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "domainAge(getDomain(\"https://www.facebook.com/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "framed-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"XY.COM\",\n",
      "    \"xy.com\"\n",
      "  ],\n",
      "  \"registrar\": \"eName Technology Co.,Ltd.\",\n",
      "  \"whois_server\": \"whois.ename.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": \"2017-09-04 02:14:58\",\n",
      "  \"creation_date\": \"1995-04-24 04:00:00\",\n",
      "  \"expiration_date\": \"2027-04-25 04:00:00\",\n",
      "  \"name_servers\": [\n",
      "    \"NS3.DNSV5.COM\",\n",
      "    \"NS4.DNSV5.COM\",\n",
      "    \"ns3.dnsv5.com\",\n",
      "    \"ns4.dnsv5.com\"\n",
      "  ],\n",
      "  \"status\": [\n",
      "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "    \"clientDeleteProhibited https://www.icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://www.icann.org/epp#clientTransferProhibited\"\n",
      "  ],\n",
      "  \"emails\": \"abuse@ename.com\",\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": null,\n",
      "  \"org\": null,\n",
      "  \"address\": null,\n",
      "  \"city\": null,\n",
      "  \"state\": \"shang hai\",\n",
      "  \"zipcode\": null,\n",
      "  \"country\": \"CN\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import whois \n",
    "def is_registered(domain_name):\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return bool(w.domain_name)\n",
    "def domain_object(domain_name):\n",
    "    if is_registered(domain_name):\n",
    "        whois_info = whois.whois(domain_name)\n",
    "        return whois_info\n",
    "print(fun(\"xy.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indie-reception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    #print(ageofdomain)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "domainAge(fun(\"facebook.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "packed-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "    print(\"*\")  \n",
    "    return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = ((expiration_date - today).days)\n",
    "    print(end)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end\n",
    "domainEnd(domain_object(\"facebook.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "suspended-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "\"\"\"### **3.3.1. IFrame Redirection**\n",
    "\n",
    "IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation. \n",
    "\n",
    "If the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "\n",
    "def iframe(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    print(response)\n",
    "    if response == \"\":\n",
    "      return 1\n",
    "    else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1\n",
    "iframe(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unavailable-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "choice-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['www.facebook.com', 0, False, 0, 0, 0, 0, 0, 0, False, 1, 1, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from urllib.parse import urlparse  # Used in 1,5,7\n",
    "import re  # Used in 2,8 -- Regular expression operations\n",
    "\n",
    "#1\n",
    "def getDomain(url):\n",
    "    result= urlparse(url)\n",
    "    \n",
    "    domain = result.netloc\n",
    "    \n",
    "    if \"www.\" in domain:\n",
    "        domain.replace(\"www.\",\"\")\n",
    "    \n",
    "    return domain\n",
    "\n",
    "#2\n",
    "def havingIp(url):\n",
    "    if re.match(r\"http://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/.*\" , url ):\n",
    "        return 1\n",
    "    return 0   \n",
    "\n",
    "#3\n",
    "def havingAtSign(url):\n",
    "    return '@' in url    # False if @ not not present else True \n",
    "\n",
    "#4\n",
    "def urlLengthFactor(url):\n",
    "    url_length = len(url)\n",
    "    if url_length<54:\n",
    "        return 0\n",
    "    \n",
    "    elif 54<=url_length<=75:\n",
    "        return 1\n",
    "    \n",
    "    return 2     # 0 -> legitimate 1->suspicious  2->Phishing\n",
    "\n",
    "\n",
    "#5\n",
    "def getDepth(url):\n",
    "    url_path=urlparse(url).path\n",
    "    print(url_path)\n",
    "    url_parts=url_path.split('/')\n",
    "    url_depth=0\n",
    "    \n",
    "    for i in url_parts:\n",
    "        if i!=\"\" :\n",
    "            url_depth+=1\n",
    "    \n",
    "    return url_depth            # Return the depth of url using no. of subdirectory in url path\n",
    "\n",
    "\n",
    "#6\n",
    "def reDirection(url):\n",
    "    pos = url.rfind(\"//\")    #Finds last occurence of // in url\n",
    "    \n",
    "    if pos<7:\n",
    "        return 0\n",
    "    \n",
    "    if url[:5].upper()==\"HTTPS\" and pos==7:\n",
    "        return 0\n",
    "    \n",
    "    return 1    # only 1 // must be present and that only at index less than 7\n",
    "\n",
    "\n",
    "\n",
    "#7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain) \n",
    "\n",
    "def httpDomain(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    if 'https' in domain:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#example- tinyURL(\"https://bitly.com/\") return 1\n",
    "\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n",
    "    #print(urlparse(url).netloc)\n",
    "#example- tinyURL(\"https://bit-ly.com/\") return 1\n",
    "\n",
    "# 10. Whether domain is registered or not \n",
    "def is_registered(domain_name):\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    return bool(w.domain_name)\n",
    "   \n",
    "# 11. To get domain object\n",
    "def domain_object(domain_name):\n",
    "    if is_registered(domain_name):\n",
    "        whois_info = whois.whois(domain_name)\n",
    "        return whois_info\n",
    "    return None\n",
    "    \n",
    "\"\"\"#### **Age of Domain**\n",
    "\n",
    "This feature can be extracted from WHOIS database. Most phishing websites live for a short period of time. The minimum age of the legitimate domain is considered to be 12 months for this project. Age here is nothing but different between creation and expiration time.\n",
    "\n",
    "If age of domain > 12 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "# 12.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_object):\n",
    "    try:\n",
    "        creation_date = domain_object.creation_date\n",
    "        expiration_date = domain_object.expiration_date\n",
    "    except:\n",
    "        return 1\n",
    "        \n",
    "    if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "        try:\n",
    "            creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return 1\n",
    "    if ((expiration_date is None) or (creation_date is None)):\n",
    "        return 1\n",
    "    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "        return 1\n",
    "    else:\n",
    "        ageofdomain = abs((expiration_date - creation_date).days)\n",
    "        if ((ageofdomain/30) < 6):\n",
    "            age = 1\n",
    "        else:\n",
    "            age = 0\n",
    "    return age\n",
    "\n",
    "\"\"\"#### **End Period of Domain??????????**\n",
    "\n",
    "This feature can be extracted from WHOIS database. For this feature, the remaining domain time is calculated by finding the different between expiration time & current time. The end period considered for the legitimate domain is 6 months or less  for this project. \n",
    "\n",
    "If end period of domain > 6 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_object):\n",
    "    try:\n",
    "        expiration_date = domain_object.expiration_date\n",
    "    except:\n",
    "        return 1\n",
    "    if isinstance(expiration_date,str):\n",
    "        try:\n",
    "            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return 1\n",
    "    if (expiration_date is None):\n",
    "        return 1\n",
    "    elif (type(expiration_date) is list):\n",
    "        return 1\n",
    "    else:\n",
    "        today = datetime.now()\n",
    "        end = abs((expiration_date - today).days)\n",
    "        if ((end/30) < 6):\n",
    "            end = 0\n",
    "        else:\n",
    "            end = 1\n",
    "    return end\n",
    "\n",
    "\"\"\"## **3.HTML and JavaScript based Features**\n",
    "\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "*   IFrame Redirection\n",
    "*   Status Bar Customization\n",
    "*   Disabling Right Click\n",
    "*   Website Forwarding\n",
    "\n",
    "Each of these features are explained and the coded below:\n",
    "\"\"\"\n",
    "# importing required packages for this section\n",
    "import requests\n",
    "\n",
    "\"\"\"### **IFrame Redirection**\n",
    "\n",
    "IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation. \n",
    "\n",
    "If the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\"\"\"### **Status Bar Customization**\n",
    "\n",
    "Phishers may use JavaScript to show a fake URL in the status bar to users. To extract this feature, we must dig-out the webpage source code, particularly the “onMouseOver” event, and check if it makes any changes on the status bar\n",
    "\n",
    "If the response is empty or onmouseover is found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "    if response == \"\" :\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\"\"\"### **Disabling Right Click**\n",
    "\n",
    "Phishers use JavaScript to disable the right-click function, so that users cannot view and save the webpage source code. This feature is treated exactly as “Using onMouseOver to hide the Link”. Nonetheless, for this feature, we will search for event “event.button==2” in the webpage source code and check if the right click is disabled.\n",
    "\n",
    "If the response is empty or onmouseover is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\"\"\"### ** Website Forwarding**\n",
    "The fine line that distinguishes phishing websites from legitimate ones is how many times a website has been redirected. In our dataset, we find that legitimate websites have been redirected one time max. On the other hand, phishing websites containing this feature have been redirected at least 4 times.\n",
    "\"\"\"\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if len(response.history) <= 2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def extractFeatures(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        \n",
    "        \n",
    "    return [getDomain(url) , havingIp(url) , havingAtSign(url) , urlLengthFactor(url) ,getDepth(url) , reDirection(url) , httpDomain(url) ,tinyURL(url) , prefixSuffix(url) , is_registered(getDomain(url)) , domainAge(domain_object(getDomain(url))) , domainEnd(domain_object(getDomain(url))) , iframe(response) , mouseOver(response) , rightClick(response) , forwarding(response) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extractFeatures(\"https://www.facebook.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "protected-freedom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/torrent/1110018/Blackhat-2015-RUSSIAN-720p-WEB-DL-DD5-1-H264-RUFGT/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from urllib.parse import urlparse  # Used in 1,5,7\n",
    "import re  # Used in 2,8 -- Regular expression operations\n",
    "\n",
    "#1\n",
    "def getDomain(url):\n",
    "    result= urlparse(url)\n",
    "    \n",
    "    domain = result.netloc\n",
    "    \n",
    "    if \"www.\" in domain:\n",
    "        domain.replace(\"www.\",\"\")\n",
    "    \n",
    "    return domain\n",
    "\n",
    "#2\n",
    "def havingIp(url):\n",
    "    if re.match(r\"http://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/.*\" , url ):\n",
    "        return 1\n",
    "    return 0   \n",
    "\n",
    "#3\n",
    "def havingAtSign(url):\n",
    "    return 1 if '@' in url else 0    # 0 if @ not not present else True \n",
    "\n",
    "#4\n",
    "def urlLengthFactor(url):\n",
    "    url_length = len(url)\n",
    "    if url_length<54:\n",
    "        return 0\n",
    "    \n",
    "    elif 54<=url_length<=75:\n",
    "        return 1\n",
    "    \n",
    "    return 2     # 0 -> legitimate 1->suspicious  2->Phishing\n",
    "\n",
    "\n",
    "#5\n",
    "def getDepth(url):\n",
    "    url_path=urlparse(url).path\n",
    "    print(url_path)\n",
    "    url_parts=url_path.split('/')\n",
    "    url_depth=0\n",
    "    \n",
    "    for i in url_parts:\n",
    "        if i!=\"\" :\n",
    "            url_depth+=1\n",
    "    \n",
    "    return url_depth            # Return the depth of url using no. of subdirectory in url path\n",
    "\n",
    "\n",
    "#6\n",
    "def reDirection(url):\n",
    "    pos = url.rfind(\"//\")    #Finds last occurence of // in url\n",
    "    \n",
    "    if pos<7:\n",
    "        return 0\n",
    "    \n",
    "    if url[:5].upper()==\"HTTPS\" and pos==7:\n",
    "        return 0\n",
    "    \n",
    "    return 1    # only 1 // must be present and that only at index less than 7\n",
    "\n",
    "\n",
    "\n",
    "#7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain) \n",
    "\n",
    "def httpDomain(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    if 'https' in domain:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#example- tinyURL(\"https://bitly.com/\") return 1\n",
    "\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n",
    "    #print(urlparse(url).netloc)\n",
    "#example- tinyURL(\"https://bit-ly.com/\") return 1\n",
    "\n",
    "# 10. Whether domain is registered or not \n",
    "def is_registered(domain_name):\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "    except Exception:\n",
    "        return 0\n",
    "    \n",
    "    return 1 if bool(w.domain_name) else 0\n",
    "   \n",
    "# 11. To get domain object\n",
    "def domain_object(domain_name):\n",
    "    if is_registered(domain_name):\n",
    "        whois_info = whois.whois(domain_name)\n",
    "        return whois_info\n",
    "    return None\n",
    "    \n",
    "\"\"\"#### **Age of Domain**\n",
    "\n",
    "This feature can be extracted from WHOIS database. Most phishing websites live for a short period of time. The minimum age of the legitimate domain is considered to be 12 months for this project. Age here is nothing but different between creation and expiration time.\n",
    "\n",
    "If age of domain > 12 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "# 12.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_object):\n",
    "    try:\n",
    "        creation_date = domain_object.creation_date\n",
    "        expiration_date = domain_object.expiration_date\n",
    "    except:\n",
    "        return 1\n",
    "        \n",
    "    if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "        try:\n",
    "            creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return 1\n",
    "    if ((expiration_date is None) or (creation_date is None)):\n",
    "        return 1\n",
    "    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "        return 1\n",
    "    else:\n",
    "        ageofdomain = abs((expiration_date - creation_date).days)\n",
    "        if ((ageofdomain/30) < 6):\n",
    "            age = 1\n",
    "        else:\n",
    "            age = 0\n",
    "    return age\n",
    "\n",
    "\"\"\"#### **End Period of Domain??????????**\n",
    "\n",
    "This feature can be extracted from WHOIS database. For this feature, the remaining domain time is calculated by finding the different between expiration time & current time. The end period considered for the legitimate domain is 6 months or less  for this project. \n",
    "\n",
    "If end period of domain > 6 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_object):\n",
    "    try:\n",
    "        expiration_date = domain_object.expiration_date\n",
    "    except:\n",
    "        return 1\n",
    "    if isinstance(expiration_date,str):\n",
    "        try:\n",
    "            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return 1\n",
    "    if (expiration_date is None):\n",
    "        return 1\n",
    "    elif (type(expiration_date) is list):\n",
    "        return 1\n",
    "    else:\n",
    "        today = datetime.now()\n",
    "        end = abs((expiration_date - today).days)\n",
    "        if ((end/30) < 6):\n",
    "            end = 0\n",
    "        else:\n",
    "            end = 1\n",
    "    return end\n",
    "\n",
    "\"\"\"## **3.HTML and JavaScript based Features**\n",
    "\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "*   IFrame Redirection\n",
    "*   Status Bar Customization\n",
    "*   Disabling Right Click\n",
    "*   Website Forwarding\n",
    "\n",
    "Each of these features are explained and the coded below:\n",
    "\"\"\"\n",
    "# importing required packages for this section\n",
    "import requests\n",
    "\n",
    "\"\"\"### **IFrame Redirection**\n",
    "\n",
    "IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation. \n",
    "\n",
    "If the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\"\"\"### **Status Bar Customization**\n",
    "\n",
    "Phishers may use JavaScript to show a fake URL in the status bar to users. To extract this feature, we must dig-out the webpage source code, particularly the “onMouseOver” event, and check if it makes any changes on the status bar\n",
    "\n",
    "If the response is empty or onmouseover is found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "    if response == \"\" :\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\"\"\"### **Disabling Right Click**\n",
    "\n",
    "Phishers use JavaScript to disable the right-click function, so that users cannot view and save the webpage source code. This feature is treated exactly as “Using onMouseOver to hide the Link”. Nonetheless, for this feature, we will search for event “event.button==2” in the webpage source code and check if the right click is disabled.\n",
    "\n",
    "If the response is empty or onmouseover is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\"\"\"### ** Website Forwarding**\n",
    "The fine line that distinguishes phishing websites from legitimate ones is how many times a website has been redirected. In our dataset, we find that legitimate websites have been redirected one time max. On the other hand, phishing websites containing this feature have been redirected at least 4 times.\n",
    "\"\"\"\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if len(response.history) <= 2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def extractFeatures(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        \n",
    "        \n",
    "    return [getDomain(url) , havingIp(url) , havingAtSign(url) , urlLengthFactor(url) ,getDepth(url) , reDirection(url) , httpDomain(url) ,tinyURL(url) , prefixSuffix(url) , is_registered(getDomain(url)) , domainAge(domain_object(getDomain(url))) , domainEnd(domain_object(getDomain(url))) , iframe(response) , mouseOver(response) , rightClick(response) , forwarding(response) ]\n",
    "\n",
    "\n",
    "\n",
    "extractFeatures(\"/torrent/1110018/Blackhat-2015-RUSSIAN-720p-WEB-DL-DD5-1-H264-RUFGT/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chief-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def domainAge(domain_object):\n",
    "    if domain_object==None:\n",
    "        return 1\n",
    "    try:\n",
    "        creation_date = domain_object.creation_date\n",
    "        expiration_date = domain_object.expiration_date\n",
    "    except:\n",
    "        return 1\n",
    "        \n",
    "    if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "        try:\n",
    "            creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return 1\n",
    "    if ((expiration_date is None) or (creation_date is None)):\n",
    "        return 1\n",
    "    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "        return 1\n",
    "    else:\n",
    "        ageofdomain = abs((expiration_date - creation_date).days)\n",
    "        if ((ageofdomain/30) < 6):\n",
    "            age = 1\n",
    "        else:\n",
    "            age = 0\n",
    "    return age\n",
    "\n",
    "domainAge(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incomplete-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facebook.com', 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse,urlencode\n",
    "import ipaddress\n",
    "import re\n",
    "\n",
    "\"\"\"#### **3.1.1. Domain of the URL**\n",
    "Here, we are just extracting the domain present in the URL. This feature doesn't have much significance in the training. May even be dropped while training the model.\n",
    "\"\"\"\n",
    "# 1.Domain of the URL (Domain) \n",
    "def getDomain(url):  \n",
    "  domain = urlparse(url).netloc\n",
    "  if re.match(r\"^www.\",domain):\n",
    "\t       domain = domain.replace(\"www.\",\"\")\n",
    "  return domain\n",
    "\n",
    "\"\"\"#### **3.1.2. IP Address in the URL**\n",
    "Checks for the presence of IP address in the URL. URLs may have IP address instead of domain name. If an IP address is used as an alternative of the domain name in the URL, we can be sure that someone is trying to steal personal information with this URL.\n",
    "If the domain part of URL has IP address, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip\n",
    "\n",
    "\"\"\"#### **3.1.3. \"@\" Symbol in URL**\n",
    "Checks for the presence of '@' symbol in the URL. Using “@” symbol in the URL leads the browser to ignore everything preceding the “@” symbol and the real address often follows the “@” symbol. \n",
    "If the URL has '@' symbol, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1    \n",
    "  else:\n",
    "    at = 0    \n",
    "  return at\n",
    "\n",
    "\"\"\"#### **3.1.4. Length of URL**\n",
    "Computes the length of the URL. Phishers can use long URL to hide the doubtful part in the address bar. In this project, if the length of the URL is greater than or equal 54 characters then the URL classified as phishing otherwise legitimate.\n",
    "If the length of URL >= 54 , the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0            \n",
    "  else:\n",
    "    length = 1            \n",
    "  return length\n",
    "\n",
    "\"\"\"#### **3.1.5. Depth of URL**\n",
    "Computes the depth of the URL. This feature calculates the number of sub pages in the given url based on the '/'.\n",
    "The value of feature is a numerical based on the URL.\n",
    "\"\"\"\n",
    "\n",
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth\n",
    "\n",
    "\"\"\"#### **3.1.6. Redirection \"//\" in URL**\n",
    "Checks the presence of \"//\" in the URL. The existence of “//” within the URL path means that the user will be redirected to another website. The location of the “//” in URL is computed. We find that if the URL starts with “HTTP”, that means the “//” should appear in the sixth position. However, if the URL employs “HTTPS” then the “//” should appear in seventh position.\n",
    "If the \"//\" is anywhere in the URL apart from after the protocal, thee value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\"\"\"#### **3.1.7. \"http/https\" in Domain name**\n",
    "Checks for the presence of \"http/https\" in the domain part of the URL. The phishers may add the “HTTPS” token to the domain part of a URL in order to trick users.\n",
    "If the URL has \"http/https\" in the domain part, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\"\"\"#### **3.1.8. Using URL Shortening Services “TinyURL”**\n",
    "URL shortening is a method on the “World Wide Web” in which a URL may be made considerably smaller in length and still lead to the required webpage. This is accomplished by means of an “HTTP Redirect” on a domain name that is short, which links to the webpage that has a long URL. \n",
    "If the URL is using Shortening Services, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\"\"\"#### **3.1.9. Prefix or Suffix \"-\" in Domain**\n",
    "Checking the presence of '-' in the domain part of URL. The dash symbol is rarely used in legitimate URLs. Phishers tend to add prefixes or suffixes separated by (-) to the domain name so that users feel that they are dealing with a legitimate webpage. \n",
    "If the URL has '-' symbol in the domain part of the URL, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n",
    "\n",
    "\"\"\"### **3.2. Domain Based Features:**\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "*   DNS Record\n",
    "*   Website Traffic \n",
    "*   Age of Domain\n",
    "*   End Period of Domain\n",
    "Each of these features are explained and the coded below:\n",
    "\"\"\"\n",
    "\n",
    "#!pip install python-whois\n",
    "\n",
    "# importing required packages for this section\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "#import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\"#### **3.2.1. DNS Record**\n",
    "For phishing websites, either the claimed identity is not recognized by the WHOIS database or no records founded for the hostname. \n",
    "If the DNS record is empty or not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 11.DNS Record availability (DNS_Record)\n",
    "# obtained in the featureExtraction function itself\n",
    "\n",
    "\"\"\"#### **3.2.2. Web Traffic**\n",
    "This feature measures the popularity of the website by determining the number of visitors and the number of pages they visit. However, since phishing websites live for a short period of time, they may not be recognized by the Alexa database (Alexa the Web Information Company., 1996). By reviewing our dataset, we find that in worst scenarios, legitimate websites ranked among the top 100,000. Furthermore, if the domain has no traffic or is not recognized by the Alexa database, it is classified as “Phishing”.\n",
    "If the rank of the domain < 100000, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"#### **3.2.3. Age of Domain**\n",
    "This feature can be extracted from WHOIS database. Most phishing websites live for a short period of time. The minimum age of the legitimate domain is considered to be 12 months for this project. Age here is nothing but different between creation and expiration time.\n",
    "If age of domain > 12 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "\n",
    "\"\"\"#### **3.2.4. End Period of Domain**\n",
    "This feature can be extracted from WHOIS database. For this feature, the remaining domain time is calculated by finding the different between expiration time & current time. The end period considered for the legitimate domain is 6 months or less  for this project. \n",
    "If end period of domain > 6 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end\n",
    "\n",
    "\"\"\"## **3.3. HTML and JavaScript based Features**\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "*   IFrame Redirection\n",
    "*   Status Bar Customization\n",
    "*   Disabling Right Click\n",
    "*   Website Forwarding\n",
    "Each of these features are explained and the coded below:\n",
    "\"\"\"\n",
    "\n",
    "# importing required packages for this section\n",
    "import requests\n",
    "\n",
    "\"\"\"### **3.3.1. IFrame Redirection**\n",
    "IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation. \n",
    "If the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1\n",
    "\n",
    "\"\"\"### **3.3.2. Status Bar Customization**\n",
    "Phishers may use JavaScript to show a fake URL in the status bar to users. To extract this feature, we must dig-out the webpage source code, particularly the “onMouseOver” event, and check if it makes any changes on the status bar\n",
    "If the response is empty or onmouseover is found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "\"\"\"### **3.3.3. Disabling Right Click**\n",
    "Phishers use JavaScript to disable the right-click function, so that users cannot view and save the webpage source code. This feature is treated exactly as “Using onMouseOver to hide the Link”. Nonetheless, for this feature, we will search for event “event.button==2” in the webpage source code and check if the right click is disabled.\n",
    "If the response is empty or onmouseover is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\"\"\"\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "\"\"\"### **3.3.4. Website Forwarding**\n",
    "The fine line that distinguishes phishing websites from legitimate ones is how many times a website has been redirected. In our dataset, we find that legitimate websites have been redirected one time max. On the other hand, phishing websites containing this feature have been redirected at least 4 times.\n",
    "\"\"\"\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "\"\"\"## **4. Computing URL Features**\n",
    "Create a list and a function that calls the other functions and stores all the features of the URL in the list. We will extract the features of each URL and append to this list.\n",
    "\"\"\"\n",
    "\n",
    "#Function to extract features\n",
    "def extractFeatures(url):\n",
    "\n",
    "  features = []\n",
    "  #Address bar based features (10)\n",
    "  features.append(getDomain(url))\n",
    "  features.append(havingIP(url))\n",
    "  features.append(haveAtSign(url))\n",
    "  features.append(getLength(url))\n",
    "  features.append(getDepth(url))\n",
    "  features.append(redirection(url))\n",
    "  features.append(httpDomain(url))\n",
    "  features.append(tinyURL(url))\n",
    "  features.append(prefixSuffix(url))\n",
    "  \n",
    "  #Domain based features (4)\n",
    "  dns = 0\n",
    "  try:\n",
    "    domain_name = whois.whois(urlparse(url).netloc)\n",
    "  except:\n",
    "    dns = 1\n",
    "\n",
    "  features.append(dns)\n",
    "  #features.append(web_traffic(url))\n",
    "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "  \n",
    "  # HTML & Javascript based features\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except:\n",
    "    response = \"\"\n",
    "\n",
    "  features.append(iframe(response))\n",
    "  features.append(mouseOver(response))\n",
    "  features.append(rightClick(response))\n",
    "  features.append(forwarding(response))\n",
    "  \n",
    "  return features\n",
    "\n",
    "\n",
    "extractFeatures(\"https://facebook.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-papua",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
